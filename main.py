# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a6V5gt64wTHHnNiC_W6alH9O_vMbFk-s
"""

!pip install -q "transformers==4.41.2" "sentence-transformers==2.7.0" pandas matplotlib torch openpyxl scikit-learn huggingface_hub

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from sentence_transformers import SentenceTransformer
from huggingface_hub import snapshot_download
from sklearn.manifold import TSNE
import time
import sys
# ---------------------------------------------------------
# 1. MODEL YÃœKLEME VE VERÄ° HAZIRLIÄI
# ---------------------------------------------------------

print("1. AÅŸama: Model ve Veri HazÄ±rlanÄ±yor...")

try:
    model_path = snapshot_download(repo_id="ytu-ce-cosmos/turkish-e5-large",
                                   ignore_patterns=["*.msgpack", "*.h5", "*.ot"],
                                   resume_download=True)
    embedding_model = SentenceTransformer(model_path)
except:
  #soru ve cevaplarÄ± sayÄ±sal vektÃ¶re Ã§evirmek iÃ§in
    print("Model yÃ¼kleme hatasÄ±! LÃ¼tfen 'Runtime > Restart Session' yapÄ±n.")

# --- VERÄ° YÃœKLEME ---
try:
    df = pd.read_excel("veri seti.xlsx")
    print("âœ… 'veri seti.xlsx' baÅŸarÄ±yla yÃ¼klendi.")
except Exception as e:
    print("\n" + "="*50)
    print("ğŸš¨ KRÄ°TÄ°K HATA: 'veri seti.xlsx' DOSYASI BULUNAMADI!")
    print("="*50)
    print(f"Hata DetayÄ±: {e}")
    sys.exit("Dosya eksik olduÄŸu iÃ§in iÅŸlem sonlandÄ±rÄ±ldÄ±.")
#Etiket sÃ¼tunun iÃ§erisindeki  deÄŸerler 1 ve -1 olduÄŸu iÃ§in sayÄ±ya  Ã§evirip sonra hatalÄ± ve boÅŸ satÄ±rlar temizleniyor.
# Veri Ã–n Ä°ÅŸleme
df.columns = df.columns.str.strip()
if 'KÃ¼me' in df.columns: df['KÃ¼me'] = df['KÃ¼me'].astype(str).str.strip()
df['Etiket'] = pd.to_numeric(df['Etiket'], errors='coerce')
df = df.dropna(subset=['Etiket'])

# Embedding
task = 'Given a Turkish search query, retrieve relevant passages that answer the query'
sorular = [f"Instruct: {task}\nQuery: {q}" for q in df['Soru'].astype(str).tolist()]
cevaplar = df['Cevap'].astype(str).tolist()

soru_vecs = embedding_model.encode(sorular, normalize_embeddings=True)
cevap_vecs = embedding_model.encode(cevaplar, normalize_embeddings=True)

#Soru ve cevap metinlerini modele  verilip vektÃ¶rlere dÃ¶nÃ¼ÅŸÃ¼yor. Soru ve cevap vektÃ¶rlerini concat iÅŸlemi yaparak giriÅŸ vektÃ¶rÃ¼ oluÅŸuyor.

X_final = np.hstack((soru_vecs, cevap_vecs, np.ones((len(soru_vecs), 1)))) # Bias ekliyoruz
y_final = df['Etiket'].values.reshape(-1, 1).astype(np.float32)

#Son sÃ¼tuna 1 ekleyerek biasâ€™Ä±  iÃ§eriye katÄ±yor. (x_final)


#Excel dosyasÄ±nda â€˜KÃ¼meâ€™  sÃ¼tununda yer alan EÄŸitim/Test  isimlerine gÃ¶re veri kÃ¼mesini eÄŸitim ve test olarak ayÄ±rdÄ±m.
#EÄŸitim iÃ§in â€˜EÄŸitimâ€™ yazan satÄ±rlar,  test iÃ§in ise â€˜Testâ€™ yazan satÄ±rlar  kullanÄ±lmÄ±ÅŸtÄ±r
# Train/Test Split
train_mask = df['KÃ¼me'].str.contains('EÄŸitim', case=False, na=False)
test_mask  = df['KÃ¼me'].str.contains('Test',   case=False, na=False)

if train_mask.sum() == 0:
    n = len(df) // 2
    X_train, y_train = torch.tensor(X_final[:n]).float(),  torch.tensor(y_final[:n]).float()
    X_test,  y_test  = torch.tensor(X_final[n:]).float(),  torch.tensor(y_final[n:]).float()
else:
    X_train, y_train = torch.tensor(X_final[train_mask]).float(), torch.tensor(y_final[train_mask]).float()
    X_test,  y_test  = torch.tensor(X_final[test_mask]).float(),  torch.tensor(y_final[test_mask]).float()

# ---------------------------------------------------------
# 2. EÄÄ°TÄ°M DÃ–NGÃœSÃœ

#tanh modeli tanÄ±mlanÄ±yor
#Ã‡Ä±ktÄ±nÄ±n iÅŸaretine gÃ¶re doÄŸruluk hesabÄ± yapÄ±lÄ±r
class OdevModeli(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.linear = nn.Linear(dim, 1, bias=False)
        self.activation = nn.Tanh()
    def forward(self, x):
        return self.activation(self.linear(x))

def accuracy(y_pred, y_true):
    return (torch.sign(y_pred) == y_true).float().mean().item()


## 5 farklÄ±  baÅŸlangÄ±Ã§ aÄŸÄ±rlÄ±ÄŸÄ± ve 100 epoch ayarlanÄ±yor.
optimizers = ["GD", "SGD", "Adam"]
runs = 5
epochs = 100

full_results = {opt: [] for opt in optimizers}
weight_history = {opt: [] for opt in optimizers}

print(f"\n2. AÅŸama: EÄŸitim BaÅŸlÄ±yor ({runs} Run x {epochs} Epoch)...")
total_start = time.time()

for r in range(runs):
    initial_w = torch.randn(1, X_train.shape[1])

    for opt_name in optimizers:
        run_start = time.time()
        model = OdevModeli(X_train.shape[1])
        with torch.no_grad(): model.linear.weight.copy_(initial_w)

        # Parametreler


        if opt_name == "GD":
            optimizer = torch.optim.SGD(model.parameters(), lr=0.5)
            batch = len(X_train)
        elif opt_name == "SGD":
            optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
            batch = 1
        else: # Adam
            optimizer = torch.optim.Adam(model.parameters(), lr=0.03)
            batch = 32

        criterion = nn.MSELoss()

        #EÄŸitim dÃ¶ngÃ¼sÃ¼: her epochâ€™ta veriyi karÄ±ÅŸtÄ±rÄ±yor, optimizerâ€™a  gÃ¶re batch batch modeli gÃ¼ncelliyor.


        run_res = {'loss': [], 'acc': [], 'time': []}
        run_weights = []


        with torch.no_grad():
            run_res['acc'].append(accuracy(model(X_test), y_test))
            run_res['loss'].append(criterion(model(X_train), y_train).item())
            run_res['time'].append(0.0)
            run_weights.append(model.linear.weight.data.clone().cpu().numpy().flatten())

        loop_start = time.time()

        for epoch in range(epochs):
            perm = torch.randperm(len(X_train))
            Xs, ys = X_train[perm], y_train[perm]
            safe_batch = batch if batch > 0 else 1
            epoch_loss = 0

            for i in range(0, len(X_train), safe_batch):
                optimizer.zero_grad()
                out = model(Xs[i:i+safe_batch])
                loss = criterion(out, ys[i:i+safe_batch])
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
        #Her adÄ±mda gradient hesaplayÄ±p weight gÃ¼ncelliyor
            run_res['loss'].append(epoch_loss / (len(X_train)/safe_batch))
            run_res['time'].append(time.time() - loop_start)
#Her epochun sonunda grafikler  ve tSne iÃ§in loss, zaman, test accuracy, aÄŸÄ±rlÄ±k vektÃ¶rÃ¼ kaydediliyor
            with torch.no_grad():
                run_res['acc'].append(accuracy(model(X_test), y_test))

            run_weights.append(model.linear.weight.data.clone().cpu().numpy().flatten())

        full_results[opt_name].append(run_res)
        weight_history[opt_name].append(run_weights)

    print(f"Run {r+1}/{runs} tamamlandÄ±.")

print(f"ğŸ TÃ¼m iÅŸlemler tamamlandÄ±. Toplam SÃ¼re: {time.time()-total_start:.2f} sn")

# ---------------------------------------------------------
# 3. GRAFÄ°K Ã‡Ä°ZÄ°MLERÄ°
# ---------------------------------------------------------
print("\n3. AÅŸama: Performans Grafikleri Ã‡iziliyor...")

run_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']


#3 tanesi: her optimizer iÃ§in 5 run  + ortalama 1 tanesi: Ã¼Ã§ optimizerâ€™Ä±n  ortalama eÄŸrilerinin  karÅŸÄ±laÅŸtÄ±rmasÄ±
def plot_spaghetti(metric_key, y_label, x_key='epoch', title_prefix="", use_log=False):
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    plt.subplots_adjust(hspace=0.3, wspace=0.3)

    algo_map = {0: (0,0, 'GD'), 1: (0,1, 'SGD'), 2: (1,0, 'Adam')}

    # KONUM BELÄ°RLEME MANTIÄI
    if metric_key == 'acc':
        legend_loc = 'lower right'
    else:
        legend_loc = 'upper right'

    # 1. Bireysel Grafikler
    for idx, (r, c, name) in algo_map.items():
        ax = axes[r, c]
        runs_data = full_results[name]

        for i, run in enumerate(runs_data):
            y_val = run[metric_key]
            x_val = run['time'] if x_key == 'time' else range(len(y_val))
            ax.plot(x_val, y_val, alpha=0.5, linewidth=1.5, color=run_colors[i], label=f'Run {i+1}')

        min_len = min([len(run[metric_key]) for run in runs_data])
        avg_y = np.mean([run[metric_key][:min_len] for run in runs_data], axis=0)

        if x_key == 'time':
            avg_x = np.mean([run['time'][:min_len] for run in runs_data], axis=0)
        else:
            avg_x = range(min_len)

        ax.plot(avg_x, avg_y, 'k--', linewidth=2.5, label='Ortalama')

        ax.set_title(f"{title_prefix} - {name}")
        ax.set_xlabel('SÃ¼re (sn)' if x_key == 'time' else 'Epoch')
        ax.set_ylabel(y_label)
        ax.grid(True, alpha=0.3)
        if use_log and x_key == 'time': ax.set_xscale('log')

        # LEGEND KONUMLANDIRMA
        ax.legend(fontsize='small', loc=legend_loc)

    # 2. KarÅŸÄ±laÅŸtÄ±rma GrafiÄŸi
    ax_comp = axes[1, 1]
    comp_colors = {'GD': 'blue', 'SGD': 'green', 'Adam': 'red'}

    for name in optimizers:
        runs_data = full_results[name]
        min_len = min([len(run[metric_key]) for run in runs_data])
        avg_y = np.mean([run[metric_key][:min_len] for run in runs_data], axis=0)
        if x_key == 'time':
            avg_x = np.mean([run['time'][:min_len] for run in runs_data], axis=0)
        else:
            avg_x = range(min_len)
        ax_comp.plot(avg_x, avg_y, label=f"{name} (Ort)", color=comp_colors[name], linewidth=2.5)

    ax_comp.set_title("KarÅŸÄ±laÅŸtÄ±rma (Ortalamalar)")
    ax_comp.set_xlabel('SÃ¼re (sn)' if x_key == 'time' else 'Epoch')
    ax_comp.set_ylabel(y_label)

    # KarÅŸÄ±laÅŸtÄ±rma grafiÄŸi iÃ§in de aynÄ± konumu kullanalÄ±m
    ax_comp.legend(loc=legend_loc)

    ax_comp.grid(True, alpha=0.3)
    if use_log and x_key == 'time': ax_comp.set_xscale('log')

    plt.show()

plot_spaghetti('loss', 'Loss', x_key='epoch', title_prefix="Epoch vs Loss")
plot_spaghetti('acc', 'Accuracy', x_key='epoch', title_prefix="Epoch vs Accuracy")
plot_spaghetti('loss', 'Loss', x_key='time', title_prefix="Time vs Loss", use_log=False)
plot_spaghetti('acc', 'Accuracy', x_key='time', title_prefix="Time vs Accuracy", use_log=False)

# ---------------------------------------------------------
# 4. T-SNE YÃ–RÃœNGELERÄ°
# ---------------------------------------------------------
print("\n4. AÅŸama: T-SNE YÃ¶rÃ¼ngeleri HesaplanÄ±yor...")

all_weights_flat = []
for r in range(runs):
    for opt in optimizers:
        all_weights_flat.extend(weight_history[opt][r])

#EÄŸitim boyunca kaydedilen  tÃ¼m aÄŸÄ±rlÄ±k vektÃ¶rleri tek  listede toplanÄ±yo
tsne = TSNE(n_components=2, perplexity=40, n_iter=1500, init='pca', learning_rate='auto', random_state=42)
X_embedded = tsne.fit_transform(np.array(all_weights_flat))

plot_data = {opt: {r: [] for r in range(runs)} for opt in optimizers}
curr_idx = 0
for r in range(runs):
    for opt in optimizers:
        step_count = len(weight_history[opt][r])
        plot_data[opt][r] = X_embedded[curr_idx : curr_idx + step_count]
        curr_idx += step_count

print("Grafik Ã§iziliyor...")
plt.figure(figsize=(14, 14))

styles = {
    'GD': {'color': 'blue', 'lw': 2.0, 'alpha': 0.8, 'marker': 'o', 'ms': 5, 'markevery': 4},
    'SGD': {'color': 'green', 'lw': 1.0, 'alpha': 0.6, 'marker': '.', 'ms': 4, 'markevery': 1},
    'Adam': {'color': 'red', 'lw': 3.0, 'alpha': 0.9, 'marker': None, 'ms': 0, 'markevery': 0}
}

labels_added = []
for r in range(runs):
    start_pt = plot_data['GD'][r][0]
    plt.scatter(start_pt[0], start_pt[1], c='black', marker='x', s=100, zorder=10,
                label='BaÅŸlangÄ±Ã§ (X)' if r==0 else "")

    for opt in optimizers:
        traj = plot_data[opt][r]
        st = styles[opt]
        lbl = opt if opt not in labels_added else ""
        if lbl: labels_added.append(lbl)

        plt.plot(traj[:, 0], traj[:, 1], color=st['color'], linewidth=st['lw'],
                 alpha=st['alpha'], marker=st['marker'], markersize=st['ms'],
                 markevery=st.get('markevery', None), label=lbl)

        plt.scatter(traj[-1, 0], traj[-1, 1], facecolors=st['color'], edgecolors='black',
                    marker='*', s=150, zorder=10,
                    label='BitiÅŸ (*)' if r==0 and opt=='GD' else "")

plt.title("FarklÄ± BaÅŸlangÄ±Ã§ NoktalarÄ±ndan Optimizasyon YÃ¶rÃ¼ngeleri (t-SNE) - 100 Epoch", fontsize=16)
plt.legend(loc='best', fontsize=12)
plt.grid(True, alpha=0.3, linestyle='--')
plt.minorticks_on()
plt.tight_layout()
plt.show()
print(" TÃ¼m iÅŸlemler baÅŸarÄ±yla tamamlandÄ±!")